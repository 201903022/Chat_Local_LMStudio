# ğŸŸ¢ Manual del Proyecto "Chatsito" con DeepSeek R1 + LM Studio

Este proyecto implementa una interfaz estilo WhatsApp que permite interactuar con el modelo de lenguaje **DeepSeek R1 (distill-llama-8b)** corriendo localmente a travÃ©s de **LM Studio**, utilizando un backend en **Flask** y frontend en HTML/CSS/JS.

---

## ğŸ“ Estructura del Proyecto

```
CHATSITO/
â”œâ”€â”€ back/                 â† Backend en Python (Flask + LM Studio)
â”‚   â”œâ”€â”€ app.py           â† Servidor Flask
â”‚   â”œâ”€â”€ venv/            â† Entorno virtual Python
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ front/                â† Interfaz estilo WhatsApp
â”‚   â”œâ”€â”€ index.html       â† HTML principal
â”‚   â”œâ”€â”€ styles.css       â† Estilo del chat
â”‚   â””â”€â”€ script.js         â† LÃ³gica JS para enviar mensajes
```

---

## ğŸ”§ Requisitos

- Python 3.10+
- [LM Studio](https://lmstudio.ai) instalado con modelo `deepseek-r1-distill-llama-8b`
- Flask y dependencias (ver instalaciÃ³n)

---

## âš™ï¸ InstalaciÃ³n del Backend (carpeta `back/`)

```bash
cd back
python -m venv venv
venv\Scripts\activate  # En Windows
pip install flask flask-cors openai
pip freeze > requirements.txt
```

---

## ğŸš€ Ejecutar el Servidor

1. Abre LM Studio y carga el modelo `deepseek-r1-distill-llama-8b`.
2. AsegÃºrate de que el servidor estÃ© activo en `http://localhost:1234`.
3. Desde la carpeta `back/`, ejecuta:

```bash
python app.py
```

> El backend estarÃ¡ escuchando en `http://localhost:5000/chat`

---

## ğŸ–¼ Interfaz de Usuario (carpeta `front/`)

Abre `index.html` en tu navegador. La interfaz permite:
- Escribir mensajes al estilo WhatsApp
- Enviar mensajes al backend
- Recibir respuestas del modelo

---

## ğŸ” Funcionamiento Interno

1. JS capta el mensaje del usuario y hace `POST` a `http://localhost:5000/chat`
2. Flask recibe el mensaje, lo agrega al historial y consulta a LM Studio (vÃ­a API OpenAI-compatible).
3. El modelo responde y el backend filtra bloques `<think>...</think>`
4. El frontend muestra la respuesta tipo burbuja de chat

---

## ğŸ§  PersonalizaciÃ³n del Asistente

Puedes modificar el `system prompt` en `app.py`:
```python
messages = [{
    "role": "system",
    "content": (
        "Eres un asistente que responde en espaÃ±ol, sin mostrar razonamientos internos ni usar etiquetas <think>."
    )
}]
```

---

## ğŸ§½ Mejoras Posibles

- Guardar historial en un archivo `.txt`
- Implementar reinicio de conversaciÃ³n desde el frontend
- Agregar soporte para markdown o cÃ³digo con resaltado
- Convertir en app de escritorio (Tkinter o Electron)

---

## ğŸ§ª Ejemplo de mensaje

Usuario:
```
como hacer un hola mundo en python?
```
Respuesta:
```
Claro, aquÃ­ tienes:
```python
print("Hola Mundo")
```
```

---

## ğŸ” 100% Offline

Este proyecto es **100% local y privado**:
- El modelo corre offline en tu PC
- Flask y JS solo usan `localhost`
- No se envÃ­a informaciÃ³n a internet

---

## ğŸ“„ Licencia

Uso personal o educativo. Puedes modificarlo libremente.

---

_Desarrollado por: Jonathan A. Sanchez y DeepSeek + Flask + HTML/CSS/JS_

